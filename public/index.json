[{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536465600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536465600,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"https://kdgosik.netlify.com/tutorial/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":["Ningtao Wang","Kirk Gosik","Runze Li","Bruce Lindsay","Rongling Wu"],"categories":null,"content":"","date":1573676612,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573676612,"objectID":"54424def6486d581673e8e46ffbb5dd0","permalink":"https://kdgosik.netlify.com/publication/block-mixture/","publishdate":"2019-11-13T15:23:32-05:00","relpermalink":"/publication/block-mixture/","section":"publication","summary":"To study how genes function in a cellular and physiological process, a general procedure is to classify gene expression profiles into categories based on their similarity and reconstruct a regulatory network for functional elements. However, this procedure has not been implemented with the genetic mechanisms that underlie the organization of gene clusters and networks, despite much effort made to map expression quantitative trait loci (eQTLs) that affect the expression of individual genes. Here we address this issue by developing a computational approach that integrates gene clustering and network reconstruction with genetic mapping into a unifying framework. The approach can not only identify specific eQTLs that control how genes are clustered and organized toward biological functions, but also enable the investigation of the biological mechanisms that individual eQTLs perturb in a signaling pathway. We applied the new approach to characterize the effects of eQTLs on the structure and organization of gene clusters in Caenorhabditis elegans. This study provides the first characterization, to our knowledge, of the effects of genetic variants on the regulatory network of gene expression. The approach developed can also facilitate the genetic dissection of other dynamic processes, including development, physiology and disease progression in any organisms.","tags":[],"title":"Block Mixture","type":"publication"},{"authors":null,"categories":null,"content":" SAUCIE Journal Club  Reference Biorxiv  Exploring Single-Cell Data with Deep Multitasking Neural Networks\nPreivew of the paper on biorxiv.\nDescription Our unsupervised architecture, called SAUCIE (Sparse Autoencoder for Unsupervised Clustering, Imputation, and Embedding), simultaneously performs several key tasks for single-cell data analysis including 1) clustering, 2) batch correction, 3) visualization, and 4) denoising/imputation. SAUCIE is trained to recreate its own input after reducing its dimensionality in a 2-D embedding layer which can be used to visualize the data.\nAdditionally, SAUCIE uses two novel regularizations: (1) an information dimension regularization to penalize entropy as computed on normalized activation values of the layer, and thereby encourage binary-like encodings that are amenable to clustering and (2) a Maximal Mean Discrepancy penalty to correct batch effects. Thus SAUCIE has a single architecture that denoises, batch-corrects, visualizes and clusters data using a unified representation. We show results on artificial data where ground truth is known, as well as mass cytometry data from dengue patients, and single-cell RNA-sequencing data from embryonic mouse brain.\nArchitecture SAUCIE consists of three encoding layers, an embedding layer, and then three decoding layers.\nTraining To perform multiple tasks, SAUCIE uses a single architecture as described above, but is run and optimized sequentially. The first run imputes noisy values and corrects batch effects in the original data. This preprocessed data is then run through SAUCIE again to obtain a visualization and to pick out clusters.\nThe loss function of all runs starts with a reconstruction loss Lr forcing the autoencoder to learn to reconstruct its input at the end. SAUCIE uses the standard mean-squared error loss (i.e.,\n$$L{r}(X, \\hat{X}) = \\frac{1}{n}\\Sigma^{n}{i=1}||xi − \\hat{x{i}}||^2$$\nFour key tasks:  visualization and dimensionality reduction, batch correction, clustering, and denoising and imputation.  #### Visualization/Dimensionality Reduction\n2-D bottleneck used as embeddings for visualization.\nThis regularization is computed from the visualization layer to ensure consistency across subsampled batches. The resulting total loss is then, $$ L = L_r(X, \\hat{X}) + \\lambda_b · L_b(V )$$\nBatch Correction (page13-14, 22 and 26-27)\nThe batch correction term $L_b$ calculates the Maximal Mean Discrepancy (MMD) between batches, as\n$$Lb = \\Sigma{i\\neq{ref}}MMD(V_{ref} , V_i),$$\nwhere $V_{ref}$ is the visualization layer of one of the replicates, arbitrarily chosen to be considered as a reference batch\nClustering (page 27)\nThe loss function of the clustering run then optimizes $L_r$ along with two regularization terms $L_c$ and $L_d$ that together enable SAUCIE to learn clusters:\n$$L = L_r(\\hat{X}, \\tilde{X}) + \\lambda_c · L_c(B) + \\lambda_d · L_d(B, \\hat{X})$$\nThe two regularizations $\\lambda_d$ and $\\lambda_c$ affect the number of clusters that result. For a given value of $\\lambda_d$, as $\\lambda_c$ increases, the number of clusters decreases (coarser granularity). Higher values of $\\lambda_d$ yield more clusters (finer granularity). Notably, these results are robust and yield reasonable results for varying values of the two regularizations.\nDenoising/Imputation Download Code There is not packages to install. It is tensorflow code that is on the github page for the lab. You are able to download a zip file of the repository and save it to a directory called code. We will reference this for the functions to run SAUCIE.\n## Get code from github and download to code directory !mkdir code !wget https://github.com/KrishnaswamyLab/SAUCIE/archive/master.zip -O code/master.zip !cd code; unzip master.zip !cd ..  --2019-02-16 10:45:16-- https://github.com/KrishnaswamyLab/SAUCIE/archive/master.zip Resolving github.com... 192.30.253.113, 192.30.253.112 Connecting to github.com|192.30.253.113|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://codeload.github.com/KrishnaswamyLab/SAUCIE/zip/master [following] --2019-02-16 10:45:16-- https://codeload.github.com/KrishnaswamyLab/SAUCIE/zip/master Resolving codeload.github.com... 192.30.253.120, 192.30.253.121 Connecting to codeload.github.com|192.30.253.120|:443... connected. HTTP request sent, awaiting response... 200 OK Length: unspecified [application/zip] Saving to: ‘code/master.zip’ code/master.zip [ \u0026lt;=\u0026gt; ] 12.25K --.-KB/s in 0.02s 2019-02-16 10:45:16 (626 KB/s) - ‘code/master.zip’ saved [12541] Archive: master.zip c2e59683ddf401f07d4c226a420b367181934715 creating: SAUCIE-master/ inflating: SAUCIE-master/.gitignore inflating: SAUCIE-master/README.md inflating: SAUCIE-master/SAUCIE.py extracting: SAUCIE-master/__init__.py inflating: SAUCIE-master/example.py inflating: SAUCIE-master/loader.py inflating: SAUCIE-master/model.py inflating: SAUCIE-master/utils.py  Download 10x PBMC data We will use the PBMC data from the 10x website as our test data. You can download this and place it in a directory called data.\n!mkdir data !wget https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz -O data/pbmc3k_filtered_gene_bc_matrices.tar.gz !cd data; tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz !cd ..  --2019-02-16 10:45:19-- https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz Resolving s3-us-west-2.amazonaws.com... 52.218.209.8 Connecting to s3-us-west-2.amazonaws.com|52.218.209.8|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 7621991 (7.3M) [application/x-tar] Saving to: ‘data/pbmc3k_filtered_gene_bc_matrices.tar.gz’ data/pbmc3k_filtere 100%[===================\u0026gt;] 7.27M 3.98MB/s in 1.8s 2019-02-16 10:45:21 (3.98 MB/s) - ‘data/pbmc3k_filtered_gene_bc_matrices.tar.gz’ saved [7621991/7621991]  Requirements You will also need to have the following python modules installed to run this.\n## Python3 scanpy louvain tensorflow 1.4.0 numpy 1.13.3 scipy 1.1.0  Note: all requirements automatically satisfied in colab.research.google.com except for scanpy and louvain.\n%%time ## this takes about 5 minutes ## installing scanpy and louvain !pip install scanpy louvain tensorflow  Requirement already satisfied: scanpy in /anaconda3/envs/scanpy/lib/python3.6/site-packages (1.4) Requirement already satisfied: louvain in /anaconda3/envs/scanpy/lib/python3.6/site-packages (0.6.1) Collecting tensorflow \u001b[?25l Downloading https://files.pythonhosted.org/packages/81/07/be624c7e0a63b080a76b7f6faf417eecdc5f6480f6a740a8bcf8991bce0b/tensorflow-1.12.0-cp36-cp36m-macosx_10_11_x86_64.whl (62.0MB) \u001b[K 100% |████████████████████████████████| 62.0MB 651kB/s eta 0:00:01 \u001b[?25hRequirement already satisfied: anndata\u0026gt;=0.6.15 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (0.6.18) Requirement already satisfied: statsmodels in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (0.9.0) Requirement already satisfied: seaborn in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (0.9.0) Requirement already satisfied: patsy in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (0.5.0) Requirement already satisfied: natsort in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (5.4.0) Requirement already satisfied: networkx in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (2.2) Requirement already satisfied: joblib in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (0.13.1) Requirement already satisfied: scipy in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (1.1.0) Requirement already satisfied: matplotlib\u0026gt;=2.2 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (3.0.0) Requirement already satisfied: scikit-learn\u0026gt;=0.19.1 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (0.20.2) Requirement already satisfied: pandas\u0026gt;=0.21 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (0.23.4) Requirement already satisfied: tables in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (3.4.4) Requirement already satisfied: numba\u0026gt;=0.40.0 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (0.42.1) Requirement already satisfied: h5py in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from scanpy) (2.8.0) Requirement already satisfied: python-igraph\u0026gt;=0.7.1.0 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from louvain) (0.7.1.post6) Collecting keras-applications\u0026gt;=1.0.6 (from tensorflow) \u001b[?25l Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB) \u001b[K 100% |████████████████████████████████| 61kB 4.6MB/s ta 0:00:01 \u001b[?25hCollecting protobuf\u0026gt;=3.6.1 (from tensorflow) \u001b[?25l Downloading https://files.pythonhosted.org/packages/c7/27/133f225035b9539f2dcfebcdf9a69ff0152f56e0120160ec5c972ea7deb9/protobuf-3.6.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (1.2MB) \u001b[K 100% |████████████████████████████████| 1.2MB 8.3MB/s eta 0:00:01 \u001b[?25hCollecting grpcio\u0026gt;=1.8.6 (from tensorflow) \u001b[?25l Downloading https://files.pythonhosted.org/packages/50/11/e1a1e4912131c783f01734597150a58d75003d89aeff3ebf3d2ee5b4d36a/grpcio-1.18.0-cp36-cp36m-macosx_10_9_x86_64.whl (1.8MB) \u001b[K 100% |████████████████████████████████| 1.8MB 7.3MB/s eta 0:00:01 \u001b[?25hRequirement already satisfied: wheel\u0026gt;=0.26 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from tensorflow) (0.32.0) Collecting astor\u0026gt;=0.6.0 (from tensorflow) Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl Collecting gast\u0026gt;=0.2.0 (from tensorflow) Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz Collecting termcolor\u0026gt;=1.1.0 (from tensorflow) Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz Collecting tensorboard\u0026lt;1.13.0,\u0026gt;=1.12.0 (from tensorflow) \u001b[?25l Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB) \u001b[K 100% |████████████████████████████████| 3.1MB 6.6MB/s eta 0:00:01 \u001b[?25hRequirement already satisfied: numpy\u0026gt;=1.13.3 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from tensorflow) (1.15.4) Collecting absl-py\u0026gt;=0.1.6 (from tensorflow) \u001b[?25l Downloading https://files.pythonhosted.org/packages/31/bc/ab68120d1d89ae23b694a55fe2aece2f91194313b71f9b05a80b32d3c24b/absl-py-0.7.0.tar.gz (96kB) \u001b[K 100% |████████████████████████████████| 102kB 23.4MB/s a 0:00:01 \u001b[?25hCollecting keras-preprocessing\u0026gt;=1.0.5 (from tensorflow) \u001b[?25l Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB) \u001b[K 100% |████████████████████████████████| 61kB 6.8MB/s ta 0:00:011 \u001b[?25hRequirement already satisfied: six\u0026gt;=1.10.0 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from tensorflow) (1.11.0) Requirement already satisfied: decorator\u0026gt;=4.3.0 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from networkx-\u0026gt;scanpy) (4.3.0) Requirement already satisfied: cycler\u0026gt;=0.10 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from matplotlib\u0026gt;=2.2-\u0026gt;scanpy) (0.10.0) Requirement already satisfied: kiwisolver\u0026gt;=1.0.1 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from matplotlib\u0026gt;=2.2-\u0026gt;scanpy) (1.0.1) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u0026gt;=2.0.1 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from matplotlib\u0026gt;=2.2-\u0026gt;scanpy) (2.2.2) Requirement already satisfied: python-dateutil\u0026gt;=2.1 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from matplotlib\u0026gt;=2.2-\u0026gt;scanpy) (2.7.3) Requirement already satisfied: pytz\u0026gt;=2011k in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from pandas\u0026gt;=0.21-\u0026gt;scanpy) (2018.5) Requirement already satisfied: numexpr\u0026gt;=2.5.2 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from tables-\u0026gt;scanpy) (2.6.6) Requirement already satisfied: llvmlite\u0026gt;=0.27.0dev0 in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from numba\u0026gt;=0.40.0-\u0026gt;scanpy) (0.27.1) Requirement already satisfied: setuptools in /anaconda3/envs/scanpy/lib/python3.6/site-packages (from protobuf\u0026gt;=3.6.1-\u0026gt;tensorflow) (40.4.0) Collecting werkzeug\u0026gt;=0.11.10 (from tensorboard\u0026lt;1.13.0,\u0026gt;=1.12.0-\u0026gt;tensorflow) \u001b[?25l Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB) \u001b[K 100% |████████████████████████████████| 327kB 8.3MB/s eta 0:00:01 \u001b[?25hCollecting markdown\u0026gt;=2.6.8 (from tensorboard\u0026lt;1.13.0,\u0026gt;=1.12.0-\u0026gt;tensorflow) \u001b[?25l Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB) \u001b[K 100% |████████████████████████████████| 92kB 23.6MB/s ta 0:00:01 \u001b[?25hBuilding wheels for collected packages: gast, termcolor, absl-py Running setup.py bdist_wheel for gast ... \u001b[?25ldone \u001b[?25h Stored in directory: /Users/kgosik/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone \u001b[?25h Stored in directory: /Users/kgosik/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6 Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone \u001b[?25h Stored in directory: /Users/kgosik/Library/Caches/pip/wheels/90/db/f8/2c3101f72ef1ad434e4662853174126ce30201a3e163dcbeca Successfully built gast termcolor absl-py Installing collected packages: keras-applications, protobuf, grpcio, astor, gast, termcolor, werkzeug, markdown, tensorboard, absl-py, keras-preprocessing, tensorflow Successfully installed absl-py-0.7.0 astor-0.7.1 gast-0.2.2 grpcio-1.18.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 protobuf-3.6.1 tensorboard-1.12.2 tensorflow-1.12.0 termcolor-1.1.0 werkzeug-0.14.1 CPU times: user 1.11 s, sys: 341 ms, total: 1.45 s Wall time: 30.7 s  #!/bin/usr/python3 import scanpy.api as sc import numpy as np import pandas as pd import scipy.io import sys ## switch to code path to load module sys.path.insert(0, 'code/SAUCIE-master') from model import SAUCIE from loader import Loader  /anaconda3/envs/scanpy/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory. \u0026quot;found relative to the 'datapath' directory.\u0026quot;.format(key))  adata = sc.read_10x_mtx( './data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file var_names='gene_symbols') # use gene symbols for the variable names (variables-axis index)  ## checking shape of data adata.X  \u0026lt;2700x32738 sparse matrix of type '\u0026lt;class 'numpy.float32'\u0026gt;' with 2286884 stored elements in Compressed Sparse Row format\u0026gt;  ## transform to numpy array for running the model ## cells by genes data_np = adata.X.toarray() initial_index = adata.obs.index gene_names = adata.var_names  ## making sure shape is the same data_np.shape  (2700, 32738)  Scanpy/Seurat Tutorial of PBMC Reference\nPreprocess adata.var_names_make_unique() # this is unnecessary if using 'gene_ids' # basic filtering sc.pp.filter_cells(adata, min_genes=200) sc.pp.filter_genes(adata, min_cells=3) # identifying mito genes mito_genes = adata.var_names.str.startswith('MT-') # for each cell compute fraction of counts in mito genes vs. all genes # the `.A1` is only necessary as X is sparse (to transform to a dense array after summing) adata.obs['percent_mito'] = np.sum( adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1 # add the total counts per cell as observations-annotation to adata adata.obs['n_counts'] = adata.X.sum(axis=1).A1 ## filtering out lowly expressed genes adata = adata[adata.obs['n_genes'] \u0026lt; 2500, :] adata = adata[adata.obs['percent_mito'] \u0026lt; 0.05, :] ## normalize data sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4) sc.pp.log1p(adata) adata.raw = adata  ## identifying and filtering to highly variable genes sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) adata = adata[:, adata.var['highly_variable']] ## regressing out umi and mito sc.pp.regress_out(adata, ['n_counts', 'percent_mito']) ## scaling gene expressiong data sc.pp.scale(adata, max_value=10)  PCA sc.tl.pca(adata, svd_solver='arpack')  Neighborhood Graph sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)  Cluster sc.tl.louvain(adata)  sc.tl.paga(adata) sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph sc.tl.umap(adata, init_pos='paga')  Identify Cell Types new_cluster_names = [ 'CD4 T', 'CD14+ Monocytes', 'B', 'CD8 T', 'NK', 'FCGR3A+ Monocytes', 'Dendritic', 'Megakaryocytes'] adata.rename_categories('louvain', new_cluster_names)  ## Plotting with UMAP sc.pl.umap(adata, color = 'louvain', legend_loc = 'on data')  SAUCIE Input Parameters  SAUCIE(input_dim, lambda_b=0, lambda_c=0, layer_c=0, lambda_d=0, layers=[512,256,128,2], activation=lrelu, learning_rate=.001, restore_folder='', save_folder='', limit_gpu_fraction=.3, no_gpu=False):   \u0026quot;\u0026quot;\u0026quot; The SAUCIE model. :param input_dim: the dimensionality of the data :param lambda_b: the coefficient for the MMD regularization :param lambda_c: the coefficient for the ID regularization :param layer_c: the index of layer_dimensions that ID regularization should be applied to (usually len(layer_dimensions)-2) :param lambda_d: the coefficient for the intracluster distance regularization :param activation: the nonlinearity to use in the hidden layers :param loss: the loss function to use, one of 'mse' or 'bce' :param learning_rate: the learning_rate to use while training :param restore_folder: string of the directory where a previous model is saved, if present will return a new Python object with the old SAUCIE tensorflow graph :param save_folder: string of the directory to save SAUCIE to by default when save() is called) \u0026quot;\u0026quot;\u0026quot;  Training on PBMC Data %%time ## takes about 35 minutes on just CPU runtime at 1000 steps ## takes less than 1 minutes with GPU runtime at 1000 steps. scales linearly, eg. 10000 steps ~ 10 minutes ## https://github.com/KrishnaswamyLab/SAUCIE#usage saucie = SAUCIE(input_dim = data_np.shape[1], lambda_b=0, # default: 0 lambda_c=0, # default: 0 layer_c=0, # default: 0 lambda_d=0, # default: 0 layers=[512,256,128,2], # default: [512,256,128,2] activation='lrelu', # default: lrelu learning_rate=.001, # defaul: .001 restore_folder='', # defaul: '' save_folder='', # default: '' limit_gpu_fraction=.3, # default .3 no_gpu=False) # default: False loadtrain = Loader(data_np, shuffle=True) saucie.train(loadtrain, steps=1000)  CPU times: user 51min 7s, sys: 4min 16s, total: 55min 23s Wall time: 8min 52s  Loading Output ## Load results loadeval = Loader(data_np, shuffle=False) embedding = saucie.get_embedding(loadeval) number_of_clusters, clusters = saucie.get_clusters(loadeval) reconstruction = saucie.get_reconstruction(loadeval)  ---- Num clusters: 3 ---- Percent clustered: 0.212 ----  When creating this notebook and keeping the parameter settings the same, I go several different number of clusters each time. This ranged from 1 cluster, the full dataset, up to 9 clusters. It seems to be very inconsistent with how many clusters it chooses. You can try and use the reqularization parameters to help with the tuning and selecting of clusters.\n## Joining Embeddings from model adata.obs = adata.obs.join(pd.DataFrame(embedding, index = initial_index, columns =['SAUCIE1', 'SAUCIE2']))  ## make cluster an integer value clusters = [int(c) for c in clusters] ## Joining Cluster labels adata.obs = adata.obs.join(pd.DataFrame(clusters, index = initial_index, columns = ['SAUCIE_Cluster'], dtype = 'category')) ## gives an error related to pandas. Does not effect any of the output.  adata.obs   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    n_genes percent_mito n_counts louvain SAUCIE1 SAUCIE2 SAUCIE_Cluster   0            AAACATACAACCAC-1 781 0.030178 2419.0 CD4 T 8.476698 -2.873760 2   AAACATTGAGCTAC-1 1352 0.037936 4903.0 B 17.384949 -0.249649 0   AAACATTGATCAGC-1 1131 0.008897 3147.0 CD4 T 9.934024 -3.806074 2   AAACCGTGCTTCCG-1 960 0.017431 2639.0 CD14+ Monocytes -2.734861 -7.545496 0   AAACCGTGTATGCG-1 522 0.012245 980.0 NK 1.894840 -1.413601 0   AAACGCACTGGTAC-1 782 0.016644 2163.0 CD4 T 8.803491 -3.491647 2   AAACGCTGACCAGT-1 783 0.038161 2175.0 CD4 T 8.572388 -1.691098 1   AAACGCTGGTTCTT-1 790 0.030973 2260.0 CD8 T 7.475278 -1.813638 0   AAACGCTGTAGCCA-1 533 0.011765 1275.0 CD8 T 4.743185 -1.437270 2   AAACGCTGTTTCTG-1 550 0.029012 1103.0 FCGR3A+ Monocytes -2.435220 -2.841363 0   AAACTTGAAAAACG-1 1116 0.026316 3914.0 B 12.536373 -0.558268 0   AAACTTGATCCAGA-1 751 0.010888 2388.0 CD4 T 10.157495 -0.945649 0   AAAGAGACGAGATA-1 866 0.010788 2410.0 CD4 T 8.486689 -2.031118 0   AAAGAGACGCGAGA-1 1059 0.014177 3033.0 CD14+ Monocytes 1.703430 -7.991738 0   AAAGAGACGGACTT-1 458 0.023458 1151.0 CD8 T 6.304974 -2.142427 2   AAAGAGACGGCATT-1 335 0.023990 792.0 CD4 T 4.453256 0.249075 0   AAAGCAGATATCGG-1 1424 0.013962 4584.0 CD14+ Monocytes -3.512605 -12.618699 0   AAAGCCTGTATGCG-1 1014 0.017077 2928.0 CD4 T 9.271269 -2.972033 0   AAAGGCCTGTCTAG-1 1446 0.015283 4973.0 B 15.877410 -6.024862 0   AAAGTTTGATCACG-1 446 0.034700 1268.0 B 5.646181 1.418554 0   AAAGTTTGGGGTGA-1 1020 0.025907 3281.0 B 12.072451 0.393993 0   AAAGTTTGTAGAGA-1 417 0.015426 1102.0 CD4 T 4.598315 -0.254824 0   AAAGTTTGTAGCGT-1 878 0.024972 2683.0 CD14+ Monocytes 0.128826 -8.880854 0   AAATCAACAATGCC-1 789 0.011643 2319.0 B 9.083061 1.080260 0   AAATCAACACCAGT-1 510 0.019830 1412.0 CD4 T 6.612620 -0.164535 0   AAATCAACCAGGAG-1 824 0.022500 2800.0 CD4 T 11.187101 -0.939697 0   AAATCAACCCTATT-1 1545 0.024313 5676.0 CD4 T -4.562459 -14.477454 0   AAATCAACGGAAGC-1 996 0.017564 3473.0 CD4 T 13.164171 -0.963695 0   AAATCAACTCGCAA-1 937 0.018499 2811.0 CD4 T 9.517199 -3.321495 2   AAATCATGACCACA-1 1368 0.045785 4128.0 FCGR3A+ Monocytes -5.798370 -9.642257 0   ... ... ... ... ... ... ... ...   TTGGAGACGCTATG-1 862 0.024042 2662.0 CD14+ Monocytes 0.297886 -9.226500 0   TTGGAGACTATGGC-1 739 0.028684 1778.0 B 6.505899 0.367602 0   TTGGGAACTGAACC-1 858 0.021124 2651.0 CD4 T 10.031704 -1.399506 0   TTGGTACTACTGGT-1 1066 0.028484 3265.0 CD14+ Monocytes -4.375662 -9.680963 0   TTGGTACTCTTAGG-1 752 0.017430 2926.0 CD4 T 12.116606 -0.787481 0   TTGGTACTGAATCC-1 615 0.025337 1855.0 B 7.341644 0.941724 0   TTGGTACTGGATTC-1 721 0.019118 1883.0 B 6.738325 1.170226 0   TTGTACACGTTGTG-1 571 0.037760 1536.0 B 6.317973 0.560490 0   TTGTACACTTGCAG-1 861 0.013729 2258.0 CD4 T 8.185881 -2.871668 2   TTGTAGCTAGCTCA-1 933 0.022249 2517.0 CD4 T 7.695907 -3.052328 2   TTGTAGCTCTCTTA-1 807 0.026242 2134.0 B 6.815217 0.676778 0   TTGTCATGGACGGA-1 1082 0.018382 2176.0 NK 4.413966 -3.471612 0   TTTAGAGATCCTCG-1 820 0.013548 2362.0 B 8.096852 1.388018 0   TTTAGCTGATACCG-1 887 0.022876 2754.0 CD4 T 10.145590 -1.339698 0   TTTAGCTGGATACC-1 850 0.011002 2454.0 CD14+ Monocytes -1.483911 -7.090866 0   TTTAGCTGTACTCT-1 1567 0.021160 5671.0 Dendritic 6.417912 -15.050301 0   TTTAGGCTCCTTTA-1 803 0.023221 1981.0 CD14+ Monocytes -0.483748 -5.736931 0   TTTATCCTGTTGTG-1 1156 0.013047 3679.0 FCGR3A+ Monocytes -4.745433 -10.890655 0   TTTCACGAGGTTCA-1 721 0.013261 2036.0 CD4 T 8.847115 -0.573167 0   TTTCAGTGGAAGGC-1 692 0.015169 1780.0 CD8 T 7.151438 -1.351251 0   TTTCAGTGTCACGA-1 700 0.034314 1632.0 B 6.117057 0.733335 0   TTTCAGTGTCTATC-1 458 0.024546 937.0 CD14+ Monocytes -1.595217 -3.230395 0   TTTCAGTGTGCAGT-1 637 0.018925 1321.0 B 4.754774 1.317456 0   TTTCCAGAGGTGAG-1 873 0.006859 2187.0 CD4 T 6.421267 -2.587235 2   TTTCGAACACCTGA-1 1544 0.013019 4455.0 Dendritic 7.185830 -8.368724 0   TTTCGAACTCTCAT-1 1155 0.021104 3459.0 CD14+ Monocytes 0.709719 -9.357344 0   TTTCTACTGAGGCA-1 1227 0.009294 3443.0 B 9.201287 -1.623354 0   TTTCTACTTCCTCG-1 622 0.021971 1684.0 B 6.398504 1.296914 0   TTTGCATGAGAGGC-1 454 0.020548 1022.0 B 5.387521 0.035854 0   TTTGCATGCCTCAC-1 724 0.008065 1984.0 CD4 T 7.869697 -0.513771 0    2638 rows × 7 columns\n ## getting the reconstruction (imputed/denoised) data reconstruction_df = adata.obs.join(pd.DataFrame(reconstruction, index = initial_index, columns = gene_names), how='left')  ## only selecting the highly variable genes that were chosen from above reconstruction_df = reconstruction_df[adata.var_names]  ## checking shape matches reconstruction_df.shape  (2638, 1838)  ## checking shape matches adata.X.shape  (2638, 1838)  ## storing the reconstructiong values in the adata layers and naming it SAUCIE adata.layers['SAUCIE'] = reconstruction_df.values  Second Round (page 29)\nTo perform multiple tasks, SAUCIE uses a single architecture as described above, but is run and optimized sequentially. The first run imputes noisy values and corrects batch effects in the original data. This preprocessed data is then run through SAUCIE again to obtain a visualization and to pick out clusters.\nThis goes through the same steps above but adding the suffix \u0026lsquo;_recon\u0026rsquo; to differentiate between the two outputs.\n## save reconstruction np.save('saucie_reconstruction_round1.npy', reconstruction)  ## save index np.save('initial_index.npy', initial_index)  ## save gene names np.save('gene_names.npy', gene_names)  ## save adata object adata.write('pbmc_adata.h5ad')  ## restart kernel to clear tensorflow output ## reread previous results reconstruction = np.load('saucie_reconstruction_round1.npy') initial_index = np.load('initial_index.npy') gene_names = np.load('gene_names.npy') adata = sc.read('pbmc_adata.h5ad')  ## https://github.com/KrishnaswamyLab/SAUCIE#usage saucie_recon = SAUCIE(input_dim = reconstruction.shape[1], lambda_b=0, # default: 0 lambda_c=0, # default: 0 layer_c=0, # default: 0 lambda_d=0, # default: 0 layers=[512,256,128,2], # default: [512,256,128,2] activation='lrelu', # default: lrelu learning_rate=.001, # defaul: .001 restore_folder='', # defaul: '' save_folder='', # default: '' limit_gpu_fraction=.3, # default .3 no_gpu=False) # default: False loadtrain_recon = Loader(reconstruction, shuffle=True) saucie_recon.train(loadtrain_recon, steps=1000)  ## Load results loadeval_recon = Loader(reconstruction, shuffle=False) embedding_recon = saucie_recon.get_embedding(loadeval_recon) number_of_clusters_recon, clusters_recon = saucie_recon.get_clusters(loadeval_recon) reconstruction_recon = saucie_recon.get_reconstruction(loadeval_recon)  ---- Num clusters: 7 ---- Percent clustered: 0.427 ----  ## Joining Embeddings from model adata.obs = adata.obs.join(pd.DataFrame(embedding_recon, index = initial_index, columns =['SAUCIE1_recon', 'SAUCIE2_recon']))  ## make cluster an integer value clusters_recon = [int(c) for c in clusters_recon] ## Joining Cluster labels adata.obs = adata.obs.join(pd.DataFrame(clusters_recon, index = initial_index, columns = ['SAUCIE_Cluster_recon'], dtype = 'category')) ## gives an error related to pandas. Does not effect any of the output.  reconstruction_df = adata.obs.join(pd.DataFrame(reconstruction_recon, index = initial_index, columns = gene_names), how='left') reconstruction_df = reconstruction_df[adata.var_names] adata.layers['SAUCIE_recon'] = reconstruction_df.values  Compare Clustering Lots of varying results with the clustering. This happens to be the latest run. It seems to be the best of what I have seen so far as well.\nLouvain Labels vs SAUCIE Clusters (w/o imputation) pd.crosstab(adata.obs.louvain, adata.obs.SAUCIE_Cluster)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }   SAUCIE_Cluster 0 1 2   louvain        CD4 T 902 96 155   CD14+ Monocytes 480 0 0   B 336 4 1   CD8 T 198 4 101   NK 149 0 8   FCGR3A+ Monocytes 153 0 0   Dendritic 36 0 0   Megakaryocytes 15 0 0     Louvain Labels vs SAUCIE Clusters using Imputation as input pd.crosstab(adata.obs.louvain, adata.obs.SAUCIE_Cluster_recon)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }   SAUCIE_Cluster_recon 0 1 2 3 4 5 6   louvain            CD4 T 436 285 90 103 112 127 0   CD14+ Monocytes 349 0 0 0 0 0 131   B 323 8 2 6 1 1 0   CD8 T 179 4 9 8 5 98 0   NK 150 0 0 0 0 7 0   FCGR3A+ Monocytes 147 0 0 0 0 0 6   Dendritic 35 1 0 0 0 0 0   Megakaryocytes 15 0 0 0 0 0 0     SAUCIE Clusters (w/o imputation) vs SAUCIE Clusters (w imputation) pd.crosstab(adata.obs.SAUCIE_Cluster, adata.obs.SAUCIE_Cluster_recon)   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }   SAUCIE_Cluster_recon 0 1 2 3 4 5 6   SAUCIE_Cluster            0 1555 298 101 81 50 47 137   1 0 0 0 36 68 0 0   2 79 0 0 0 0 186 0     Compare Visualizations SAUCIE w/o Imputation sc.pl.scatter(adata, 'SAUCIE1', 'SAUCIE2', color = 'SAUCIE_Cluster')  SAUCIE w/ Imputation sc.pl.scatter(adata, 'SAUCIE1_recon', 'SAUCIE2_recon', color = 'SAUCIE_Cluster_recon')  Comparing Clusters on UMAP Dimensions sc.pl.umap(adata, color = ['louvain', 'SAUCIE_Cluster', 'SAUCIE_Cluster_recon'])   ","date":1550334134,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550334134,"objectID":"19666dee0274eb68a9f5ac2a19ccbc60","permalink":"https://kdgosik.netlify.com/tutorial/journal-club-saucie/","publishdate":"2019-02-16T11:22:14-05:00","relpermalink":"/tutorial/journal-club-saucie/","section":"tutorial","summary":"SAUCIE Journal Club  Reference Biorxiv  Exploring Single-Cell Data with Deep Multitasking Neural Networks\nPreivew of the paper on biorxiv.\nDescription Our unsupervised architecture, called SAUCIE (Sparse Autoencoder for Unsupervised Clustering, Imputation, and Embedding), simultaneously performs several key tasks for single-cell data analysis including 1) clustering, 2) batch correction, 3) visualization, and 4) denoising/imputation. SAUCIE is trained to recreate its own input after reducing its dimensionality in a 2-D embedding layer which can be used to visualize the data.","tags":null,"title":"","type":"tutorial"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\n ggplot(cars, aes(speed, dist)) + geom_point() + geom_smooth(method=\u0026#39;lm\u0026#39;,formula=y~x)  Figure 1: A ggplot.   ","date":1550188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550188800,"objectID":"3c2213496dad1368730088d44673e998","permalink":"https://kdgosik.netlify.com/post/r-markdown-hello/","publishdate":"2019-02-15T00:00:00Z","relpermalink":"/post/r-markdown-hello/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.","tags":["ggplot","regression"],"title":"R Markdown, Hello!","type":"post"},{"authors":["Kirk Gosik","Lidan Sun","Vernon M Chinchilli","Rongling Wu"],"categories":null,"content":"","date":1533154493,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533154493,"objectID":"953dcd9d12201dacefa16bb737c21261","permalink":"https://kdgosik.netlify.com/publication/ultrahigh-dim-map/","publishdate":"2018-08-01T15:14:53-05:00","relpermalink":"/publication/ultrahigh-dim-map/","section":"publication","summary":"Background: Genetic interactions involving more than two loci have been thought to affect quantitatively inherited traits and diseases more pervasively than previously appreciated. However, the detection of such high-order interactions to chart a complete portrait of genetic architecture has not been well explored.","tags":[],"title":"Ultrahigh-Dimensional Mapping","type":"publication"},{"authors":null,"categories":null,"content":"","date":1519704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519704000,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://kdgosik.netlify.com/project/external-project/","publishdate":"2018-02-27T00:00:00-04:00","relpermalink":"/project/external-project/","section":"project","summary":"Workshop course on the analysis on single cell RNA-seq data.","tags":["course","workshop","scRNA"],"title":"External Project","type":"project"},{"authors":["Miaomiao Zhang","Wenhao Bo","Fang Xu","Huan Li","Meixia Ye","Libo Jiang","Chaozhong Shi","Yaru Fu","Guomiao Zhao","Yuejiao Huang","Kirk Gosik","Dan Liang","Rongling Wu"],"categories":null,"content":"","date":1496347765,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496347765,"objectID":"05add23428296e0200368337ede88be1","permalink":"https://kdgosik.netlify.com/publication/shoot-root-covar/","publishdate":"2017-06-01T15:09:25-05:00","relpermalink":"/publication/shoot-root-covar/","section":"publication","summary":"The coordination of shoots and roots is critical for plants to adapt to changing environments by fine‐tuning energy production in leaves and the availability of water and nutrients from roots. To understand the genetic architecture of how these two organs covary during developmental ontogeny, we conducted a mapping experiment using Euphrates poplar (Populus euphratica), a so‐called hero tree able to grow in the desert. We geminated intraspecific F1 seeds of Euphrates Poplar individually in a tube to obtain a total of 370 seedlings, whose shoot and taproot lengths were measured repeatedly during the early stage of growth. By fitting a growth equation, we estimated asymptotic growth, relative growth rate, the timing of inflection point and duration of linear growth for both shoot and taproot growth. Treating these heterochronic parameters as phenotypes, a univariate mapping model detected 19 heterochronic quantitative trait loci (hQTLs), of which 15 mediate the forms of shoot growth and four mediate taproot growth. A bivariate mapping model identified 11 pleiotropic hQTLs that determine the covariation of shoot and taproot growth. Most QTLs detected reside within the region of candidate genes with various functions, thus confirming their roles in the biochemical processes underlying plant growth.","tags":[],"title":"Shoot Root Covar","type":"publication"},{"authors":["Qian Wang","Kirk Gosik","Sujuan Xing","Libo Jiang","Lidan Sun","Vernon M Chinchilli","Rongling Wu"],"categories":null,"content":"","date":1488398629,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488398629,"objectID":"b7ab14bbb4962c7f80b73dd41f3a2b84","permalink":"https://kdgosik.netlify.com/publication/epi-game/","publishdate":"2017-03-01T15:03:49-05:00","relpermalink":"/publication/epi-game/","section":"publication","summary":"Epigenetic reprogramming is thought to play a critical role in maintaining the normal development of embryos. How the methylation state of paternal and maternal genomes regulates embryogenesis depends on the interaction and coordination of the gametes of two sexes. While there is abundant research in exploring the epigenetic interactions of sperms and oocytes, a knowledge gap exists in the mechanistic quantitation of these interactions and their impact on embryo development. This review aims at formulating a modeling framework to address this gap through the integration and synthesis of evolutionary game theory and the latest discoveries of the epigenetic control of embryo development by next-generation sequencing. This framework, named epigenetic game theory or epiGame, views embryogenesis as an ecological system in which two highly distinct and specialized gametes coordinate through either cooperation or competition, or both, to maximize the fitness of embryos under Darwinian selection. By implementing a system of ordinary differential equations, epiGame quantifies the pattern and relative magnitude of the methylation effects on embryogenesis by the mechanisms of cooperation and competition. epiGame may gain new insight into reproductive biology and can be potentially applied to design personalized medicines for genetic disorder intervention.","tags":[],"title":"Epi Game","type":"publication"},{"authors":["Lidan Sun","Jing Wang","Xuli Zhu","Libo Jiang","Kirk Gosik","Mengmeng Sang","Fengsuo Sun","Tangren Cheng","Qixiang Zhang","Rongling Wu"],"categories":null,"content":"","date":1487190001,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487190001,"objectID":"a0a43b55ae393021e7464095c2697e7c","permalink":"https://kdgosik.netlify.com/publication/hpqtl/","publishdate":"2017-02-15T15:20:01-05:00","relpermalink":"/publication/hpqtl/","section":"publication","summary":"Heterophylly, i.e. morphological changes in leaves along the axis of an individual plant, is regarded as a strategy used by plants to cope with environmental change. However, little is known of the extent to which heterophylly is controlled by genes and how each underlying gene exerts its effect on heterophyllous variation. We described a geometric morphometric model that can quantify heterophylly in plants and further constructed an R-based computing platform by integrating this model into a genetic mapping and association setting. The platform, named HpQTL, allows specific quantitative trait loci mediating heterophyllous variation to be mapped throughout the genome. The statistical properties of HpQTL were examined and validated via computer simulation. Its biological relevance was demonstrated by results from a real data analysis of heterophylly in a wood plant, mei (Prunus mume). HpQTL provides a powerful tool to analyze heterophylly and its underlying genetic architecture in a quantitative manner. It also contributes a new approach for genome-wide association studies aimed to dissect the programmed regulation of plant development and evolution.","tags":[],"title":"HpQTL","type":"publication"},{"authors":[],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461124800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515819600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://kdgosik.netlify.com/post/getting-started/","publishdate":"2016-04-20T00:00:00-04:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":["Kirk Gosik","Lan Kong","Vernon M Chinchilli","Rongling Wu"],"categories":null,"content":"","date":1457117482,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1457117482,"objectID":"6f8f3cbb3699c8a80450b5517d6c5f30","permalink":"https://kdgosik.netlify.com/publication/iform/","publishdate":"2016-03-04T14:51:22-04:00","relpermalink":"/publication/iform/","section":"publication","summary":"Knowledge about how changes in gene expression are encoded by expression quantitative trait loci (eQTLs) is a key to construct the genotype–phenotype map for complex traits or diseases. Traditional eQTL mapping is to associate one transcript with a single marker at a time, thereby limiting our inference about a complete picture of the genetic architecture of gene expression. Here, we implemented an ultrahigh-dimensional variable selection model to build a computing platform that can systematically scan main effects and interaction effects among all possible loci and identify a set of significant eQTLs modulating differentiation and function of gene expression. This platform, named iFORM/eQTL, was assembled by forward-selection-based procedures to tackle complex covariance structures of gene–gene interactions. iFORM/eQTL can particularly discern the role of cis-QTLs, trans-QTLs and their epistatic interactions in gene expression. Results from the reanalysis of a published genetic and genomic data set through iFORM/eQTL gain new discoveries on the genetic origin of gene expression differentiation in Caenorhabditis elegans, which could not be detected by a traditional one-locus/one-transcript analysis approach.","tags":[],"title":"iForm","type":"publication"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"https://kdgosik.netlify.com/post/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/post/2015-07-23-r-rmarkdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"https://kdgosik.netlify.com/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]